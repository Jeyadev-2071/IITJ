{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Segmenting Customers Based on Financial Backgrounds, Poverty Levels, Spending Habits, and Income Levels\n",
    "- **Best Algorithm: Clustering**  \n",
    "  This is an **unsupervised learning problem**, where the goal is to segment customers into different groups based on their financial attributes. Clustering algorithms like **K-Means** or **Hierarchical Clustering** are well-suited for grouping similar customers without any labeled data.\n",
    "\n",
    "#### B. Automatically Recognizing Bus from Car Using a Camera\n",
    "- **Best Algorithm: Classification**  \n",
    "  This scenario involves distinguishing between two categories—bus and car—which makes it a **classification problem**. Algorithms like **Logistic Regression**, **Decision Trees**, or **Convolutional Neural Networks (CNNs)** can be used to classify the images captured by the camera.\n",
    "\n",
    "#### C. Automatically Recognize Friends Without Labeling on Facebook\n",
    "- **Best Algorithm: Unsupervised Feature Extraction**  \n",
    "  Since the goal is to recognize friends without any labeled data, **unsupervised feature extraction** is the best choice. Techniques like **Principal Component Analysis (PCA)** or clustering-based methods can be used to identify unique features of individuals in images without labels.\n",
    "\n",
    "#### D. Identifying Accomplices of a Thief Based on Call Records\n",
    "- **Best Algorithm: Association Rule Mining**  \n",
    "  This scenario requires discovering relationships between individuals based on call records, which is typical for **association rule mining**. Algorithms like the **Apriori** or **FP-Growth** are used to find frequent associations or relationships between entities, making it useful for identifying accomplices.\n",
    "\n",
    "#### E. Predicting Future Prices of Stocks Based on Volume of Sales and Price Differences\n",
    "- **Best Algorithm: Regression**  \n",
    "  Since the task is to predict a continuous numerical value (future stock prices), **regression** is the best approach. Techniques like **Linear Regression**, **Random Forest Regression**, or more advanced methods like **LSTM (Long Short-Term Memory)** for time-series forecasting are suitable for this problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PT', 'B', 'LSTAT', 'MV'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of         CRIM    ZN  INDUS  CHAS    NOX     RM        AGE     DIS  RAD  TAX  \\\n",
      "0    0.00632  18.0   2.31     0  0.538  6.575  65.199997  4.0900    1  296   \n",
      "1    0.02731   0.0   7.07     0  0.469  6.421  78.900002  4.9671    2  242   \n",
      "2    0.02729   0.0   7.07     0  0.469  7.185  61.099998  4.9671    2  242   \n",
      "3    0.03237   0.0   2.18     0  0.458  6.998  45.799999  6.0622    3  222   \n",
      "4    0.06905   0.0   2.18     0  0.458  7.147  54.200001  6.0622    3  222   \n",
      "..       ...   ...    ...   ...    ...    ...        ...     ...  ...  ...   \n",
      "501  0.06263   0.0  11.93     0  0.573  6.593  69.099998  2.4786    1  273   \n",
      "502  0.04527   0.0  11.93     0  0.573  6.120  76.699997  2.2875    1  273   \n",
      "503  0.06076   0.0  11.93     0  0.573  6.976  91.000000  2.1675    1  273   \n",
      "504  0.10959   0.0  11.93     0  0.573  6.794  89.300003  2.3889    1  273   \n",
      "505  0.04741   0.0  11.93     0  0.573  6.030  80.800003  2.5050    1  273   \n",
      "\n",
      "            PT           B  LSTAT         MV  \n",
      "0    15.300000  396.899994   4.98  24.000000  \n",
      "1    17.799999  396.899994   9.14  21.600000  \n",
      "2    17.799999  392.829987   4.03  34.700001  \n",
      "3    18.700001  394.630005   2.94  33.400002  \n",
      "4    18.700001  396.899994   5.33  36.200001  \n",
      "..         ...         ...    ...        ...  \n",
      "501  21.000000  391.989990   9.67  22.400000  \n",
      "502  21.000000  396.899994   9.08  20.600000  \n",
      "503  21.000000  396.899994   5.64  23.900000  \n",
      "504  21.000000  393.450012   6.48  22.000000  \n",
      "505  21.000000  396.899994   7.88  11.900000  \n",
      "\n",
      "[506 rows x 14 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of         CRIM    ZN  INDUS  CHAS    NOX     RM        AGE     DIS  RAD  TAX  \\\n",
      "0    0.00632  18.0   2.31     0  0.538  6.575  65.199997  4.0900    1  296   \n",
      "1    0.02731   0.0   7.07     0  0.469  6.421  78.900002  4.9671    2  242   \n",
      "2    0.02729   0.0   7.07     0  0.469  7.185  61.099998  4.9671    2  242   \n",
      "3    0.03237   0.0   2.18     0  0.458  6.998  45.799999  6.0622    3  222   \n",
      "4    0.06905   0.0   2.18     0  0.458  7.147  54.200001  6.0622    3  222   \n",
      "..       ...   ...    ...   ...    ...    ...        ...     ...  ...  ...   \n",
      "501  0.06263   0.0  11.93     0  0.573  6.593  69.099998  2.4786    1  273   \n",
      "502  0.04527   0.0  11.93     0  0.573  6.120  76.699997  2.2875    1  273   \n",
      "503  0.06076   0.0  11.93     0  0.573  6.976  91.000000  2.1675    1  273   \n",
      "504  0.10959   0.0  11.93     0  0.573  6.794  89.300003  2.3889    1  273   \n",
      "505  0.04741   0.0  11.93     0  0.573  6.030  80.800003  2.5050    1  273   \n",
      "\n",
      "            PT           B  LSTAT         MV  \n",
      "0    15.300000  396.899994   4.98  24.000000  \n",
      "1    17.799999  396.899994   9.14  21.600000  \n",
      "2    17.799999  392.829987   4.03  34.700001  \n",
      "3    18.700001  394.630005   2.94  33.400002  \n",
      "4    18.700001  396.899994   5.33  36.200001  \n",
      "..         ...         ...    ...        ...  \n",
      "501  21.000000  391.989990   9.67  22.400000  \n",
      "502  21.000000  396.899994   9.08  20.600000  \n",
      "503  21.000000  396.899994   5.64  23.900000  \n",
      "504  21.000000  393.450012   6.48  22.000000  \n",
      "505  21.000000  396.899994   7.88  11.900000  \n",
      "\n",
      "[506 rows x 14 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of         CRIM    ZN  INDUS  CHAS    NOX     RM        AGE     DIS  RAD  TAX  \\\n",
      "0    0.00632  18.0   2.31     0  0.538  6.575  65.199997  4.0900    1  296   \n",
      "1    0.02731   0.0   7.07     0  0.469  6.421  78.900002  4.9671    2  242   \n",
      "2    0.02729   0.0   7.07     0  0.469  7.185  61.099998  4.9671    2  242   \n",
      "3    0.03237   0.0   2.18     0  0.458  6.998  45.799999  6.0622    3  222   \n",
      "4    0.06905   0.0   2.18     0  0.458  7.147  54.200001  6.0622    3  222   \n",
      "..       ...   ...    ...   ...    ...    ...        ...     ...  ...  ...   \n",
      "501  0.06263   0.0  11.93     0  0.573  6.593  69.099998  2.4786    1  273   \n",
      "502  0.04527   0.0  11.93     0  0.573  6.120  76.699997  2.2875    1  273   \n",
      "503  0.06076   0.0  11.93     0  0.573  6.976  91.000000  2.1675    1  273   \n",
      "504  0.10959   0.0  11.93     0  0.573  6.794  89.300003  2.3889    1  273   \n",
      "505  0.04741   0.0  11.93     0  0.573  6.030  80.800003  2.5050    1  273   \n",
      "\n",
      "            PT           B  LSTAT         MV  \n",
      "0    15.300000  396.899994   4.98  24.000000  \n",
      "1    17.799999  396.899994   9.14  21.600000  \n",
      "2    17.799999  392.829987   4.03  34.700001  \n",
      "3    18.700001  394.630005   2.94  33.400002  \n",
      "4    18.700001  396.899994   5.33  36.200001  \n",
      "..         ...         ...    ...        ...  \n",
      "501  21.000000  391.989990   9.67  22.400000  \n",
      "502  21.000000  396.899994   9.08  20.600000  \n",
      "503  21.000000  396.899994   5.64  23.900000  \n",
      "504  21.000000  393.450012   6.48  22.000000  \n",
      "505  21.000000  396.899994   7.88  11.900000  \n",
      "\n",
      "[506 rows x 14 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM     0\n",
       "ZN       0\n",
       "INDUS    0\n",
       "CHAS     0\n",
       "NOX      0\n",
       "RM       0\n",
       "AGE      0\n",
       "DIS      0\n",
       "RAD      0\n",
       "TAX      0\n",
       "PT       0\n",
       "B        0\n",
       "LSTAT    0\n",
       "MV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM 504\n",
      "\n",
      "ZN 26\n",
      "\n",
      "INDUS 76\n",
      "\n",
      "CHAS 2\n",
      "\n",
      "NOX 81\n",
      "\n",
      "RM 446\n",
      "\n",
      "AGE 356\n",
      "\n",
      "DIS 412\n",
      "\n",
      "RAD 9\n",
      "\n",
      "TAX 66\n",
      "\n",
      "PT 46\n",
      "\n",
      "B 357\n",
      "\n",
      "LSTAT 455\n",
      "\n",
      "MV 229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    print(col,len(data[col].unique()))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: The 13 features are numerical and describe various characteristics of the Boston housing market and neighborhoods, such as:\n",
    "\n",
    "    - CRIM: Per capita crime rate by town (504 unique)\n",
    "    - ZN: Proportion of residential land zoned for lots over 25,000 sq. ft. (26 unique)\n",
    "    - INDUS: Proportion of non-retail business acres per town (76 unique)\n",
    "    - CHAS: Charles River dummy variable (1 if tract bounds river; 0 otherwise) (2 unique) (Only Discrete column)\n",
    "    - NOX: Nitric oxide concentration (parts per 10 million) (81 unique)\n",
    "    - RM: Average number of rooms per dwelling (446 unique)\n",
    "    - AGE: Proportion of owner-occupied units built before 1940 (356 unique)\n",
    "    - DIS: Weighted distances to five Boston employment centers (412 unique)\n",
    "    - RAD: Index of accessibility to radial highways (9 unique)\n",
    "    - TAX: Full-value property-tax rate per $10,000 (66 unique)\n",
    "    - PTRATIO: Pupil-teacher ratio by town (46 unique)\n",
    "    - B: 1000(Bk - 0.63)^2, where Bk is the proportion of Black people by town (357 unique)\n",
    "    - LSTAT: Percentage of lower status of the population ( 455 unique)\n",
    "    - Target Variable: \n",
    "\n",
    "MV: Median value of owner-occupied homes in $1000s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_vars = ['CHAS'] -- # Only column which has 2 unique value and by column discription considering it as a discrete column\n",
    "discrete_columns = discrete_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X = data.drop('MV', axis=1)\n",
    "y = data['MV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Linear Regression on the dataset\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "y_pred_lr = linear_reg.predict(X_test)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the input fields and generating  SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Normalize the input fields and generate a SGD regressor\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, random_state=42)\n",
    "sgd_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_sgd = sgd_reg.predict(X_test_scaled)\n",
    "\n",
    "mse_sgd = mean_squared_error(y_test, y_pred_sgd)\n",
    "r2_sgd = r2_score(y_test, y_pred_sgd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection , Linear Regression and SGD Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature selection by dropping high correlation fields\n",
    "correlation_matrix = X.corr().abs()\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Drop features with correlation greater than 0.8\n",
    "high_corr_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.8)]\n",
    "X_train_dropped = X_train.drop(high_corr_features, axis=1)\n",
    "X_test_dropped = X_test.drop(high_corr_features, axis=1)\n",
    "\n",
    "# Linear Regression and SGD Regression after removing high correlated fields\n",
    "linear_reg.fit(X_train_dropped, y_train)\n",
    "y_pred_lr_dropped = linear_reg.predict(X_test_dropped)\n",
    "mse_lr_dropped = mean_squared_error(y_test, y_pred_lr_dropped)\n",
    "r2_lr_dropped = r2_score(y_test, y_pred_lr_dropped)\n",
    "\n",
    "scaler_dropped = StandardScaler()\n",
    "X_train_dropped_scaled = scaler_dropped.fit_transform(X_train_dropped)\n",
    "X_test_dropped_scaled = scaler_dropped.transform(X_test_dropped)\n",
    "\n",
    "sgd_reg.fit(X_train_dropped_scaled, y_train)\n",
    "y_pred_sgd_dropped = sgd_reg.predict(X_test_dropped_scaled)\n",
    "mse_sgd_dropped = mean_squared_error(y_test, y_pred_sgd_dropped)\n",
    "r2_sgd_dropped = r2_score(y_test, y_pred_sgd_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: PCA on the inputs and perform regression\n",
    "pca = PCA(n_components=5)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "linear_reg.fit(X_train_pca, y_train)\n",
    "y_pred_lr_pca = linear_reg.predict(X_test_pca)\n",
    "mse_lr_pca = mean_squared_error(y_test, y_pred_lr_pca)\n",
    "r2_lr_pca = r2_score(y_test, y_pred_lr_pca)\n",
    "\n",
    "sgd_reg.fit(X_train_pca, y_train)\n",
    "y_pred_sgd_pca = sgd_reg.predict(X_test_pca)\n",
    "mse_sgd_pca = mean_squared_error(y_test, y_pred_sgd_pca)\n",
    "r2_sgd_pca = r2_score(y_test, y_pred_sgd_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One - Hot Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Model        MSE  R-Squared\n",
      "0                     Linear Regression  24.291117   0.668760\n",
      "1                        SGD Regression  24.875080   0.660796\n",
      "2  Linear Regression (Dropped Features)  25.400905   0.653626\n",
      "3     SGD Regression (Dropped Features)  25.640159   0.650364\n",
      "4               Linear Regression (PCA)  30.109735   0.589415\n",
      "5                  SGD Regression (PCA)  30.254352   0.587443\n",
      "6   Linear Regression (One-Hot Encoded)  24.291117   0.668760\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding with ColumnTransformer\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[('encoder', OneHotEncoder(handle_unknown='ignore'), discrete_columns)], remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Fit the column transformer to the training set\n",
    "X_train_encoded = column_transformer.fit_transform(X_train)\n",
    "X_test_encoded = column_transformer.transform(X_test)\n",
    "\n",
    "# Linear Regression after one-hot encoding\n",
    "linear_reg.fit(X_train_encoded, y_train)\n",
    "y_pred_lr_encoded = linear_reg.predict(X_test_encoded)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mse_lr_encoded = mean_squared_error(y_test, y_pred_lr_encoded)\n",
    "r2_lr_encoded = r2_score(y_test, y_pred_lr_encoded)\n",
    "\n",
    "# Display all results to the user\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Linear Regression\", \"SGD Regression\", \"Linear Regression (Dropped Features)\", \"SGD Regression (Dropped Features)\", \n",
    "              \"Linear Regression (PCA)\", \"SGD Regression (PCA)\", \"Linear Regression (One-Hot Encoded)\"],\n",
    "    \"MSE\": [mse_lr, mse_sgd, mse_lr_dropped, mse_sgd_dropped, mse_lr_pca, mse_sgd_pca, mse_lr_encoded],\n",
    "    \"R-Squared\": [r2_lr, r2_sgd, r2_lr_dropped, r2_sgd_dropped, r2_lr_pca, r2_sgd_pca, r2_lr_encoded]\n",
    "})\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna Hyperparmater search on KNN, RF, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', 1, 30)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    p = trial.suggest_int('p', 1, 2)\n",
    "\n",
    "    model = KNeighborsRegressor(n_neighbors=n_neighbors, weights=weights, p=p)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "    return score\n",
    "\n",
    "def rf_objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "    return score\n",
    "\n",
    "def ridge_objective(trial):\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
    "    solver = trial.suggest_categorical('solver', ['auto', 'svd', 'cholesky', 'lsqr', 'sag'])\n",
    "\n",
    "    model = Ridge(alpha=alpha, solver=solver, random_state=42)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-29 21:45:38,795] A new study created in memory with name: no-name-38188f46-44d3-4e96-bd21-842279997fca\n",
      "[I 2024-11-29 21:45:38,812] Trial 0 finished with value: 0.4274892160676155 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'p': 2}. Best is trial 0 with value: 0.4274892160676155.\n",
      "[I 2024-11-29 21:45:38,822] Trial 1 finished with value: 0.5103165446659788 and parameters: {'n_neighbors': 21, 'weights': 'distance', 'p': 1}. Best is trial 1 with value: 0.5103165446659788.\n",
      "[I 2024-11-29 21:45:38,833] Trial 2 finished with value: 0.46286950446185016 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'p': 2}. Best is trial 1 with value: 0.5103165446659788.\n",
      "[I 2024-11-29 21:45:38,844] Trial 3 finished with value: 0.5105888212469942 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'p': 1}. Best is trial 3 with value: 0.5105888212469942.\n",
      "[I 2024-11-29 21:45:38,856] Trial 4 finished with value: 0.4699322922453543 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'p': 2}. Best is trial 3 with value: 0.5105888212469942.\n",
      "[I 2024-11-29 21:45:38,871] Trial 5 finished with value: 0.34818556215510066 and parameters: {'n_neighbors': 24, 'weights': 'uniform', 'p': 1}. Best is trial 3 with value: 0.5105888212469942.\n",
      "[I 2024-11-29 21:45:38,885] Trial 6 finished with value: 0.44897063951709926 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'p': 1}. Best is trial 3 with value: 0.5105888212469942.\n",
      "[I 2024-11-29 21:45:38,896] Trial 7 finished with value: 0.3154358133287409 and parameters: {'n_neighbors': 19, 'weights': 'uniform', 'p': 2}. Best is trial 3 with value: 0.5105888212469942.\n",
      "[I 2024-11-29 21:45:38,908] Trial 8 finished with value: 0.5618194115338764 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'p': 1}. Best is trial 8 with value: 0.5618194115338764.\n",
      "[I 2024-11-29 21:45:38,919] Trial 9 finished with value: 0.48229428993812345 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'p': 2}. Best is trial 8 with value: 0.5618194115338764.\n",
      "[I 2024-11-29 21:45:38,935] Trial 10 finished with value: 0.4720078806530113 and parameters: {'n_neighbors': 29, 'weights': 'distance', 'p': 1}. Best is trial 8 with value: 0.5618194115338764.\n",
      "[I 2024-11-29 21:45:38,948] Trial 11 finished with value: 0.47150136257674163 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'p': 1}. Best is trial 8 with value: 0.5618194115338764.\n",
      "[I 2024-11-29 21:45:38,962] Trial 12 finished with value: 0.5236416203646869 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'p': 1}. Best is trial 8 with value: 0.5618194115338764.\n",
      "[I 2024-11-29 21:45:38,978] Trial 13 finished with value: 0.5757736975624713 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'p': 1}. Best is trial 13 with value: 0.5757736975624713.\n",
      "[I 2024-11-29 21:45:38,991] Trial 14 finished with value: 0.45933439453322134 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'p': 1}. Best is trial 13 with value: 0.5757736975624713.\n",
      "[I 2024-11-29 21:45:39,007] Trial 15 finished with value: 0.5757736975624713 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'p': 1}. Best is trial 13 with value: 0.5757736975624713.\n",
      "[I 2024-11-29 21:45:39,022] Trial 16 finished with value: 0.4358830455464958 and parameters: {'n_neighbors': 15, 'weights': 'uniform', 'p': 1}. Best is trial 13 with value: 0.5757736975624713.\n",
      "[I 2024-11-29 21:45:39,036] Trial 17 finished with value: 0.5866051478518408 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'p': 1}. Best is trial 17 with value: 0.5866051478518408.\n",
      "[I 2024-11-29 21:45:39,050] Trial 18 finished with value: 0.5956019045779406 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'p': 1}. Best is trial 18 with value: 0.5956019045779406.\n",
      "[I 2024-11-29 21:45:39,065] Trial 19 finished with value: 0.45933439453322134 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'p': 1}. Best is trial 18 with value: 0.5956019045779406.\n",
      "[I 2024-11-29 21:45:39,080] Trial 20 finished with value: 0.457233605459433 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'p': 2}. Best is trial 18 with value: 0.5956019045779406.\n",
      "[I 2024-11-29 21:45:39,094] Trial 21 finished with value: 0.5956019045779406 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'p': 1}. Best is trial 18 with value: 0.5956019045779406.\n",
      "[I 2024-11-29 21:45:39,109] Trial 22 finished with value: 0.5956019045779406 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'p': 1}. Best is trial 18 with value: 0.5956019045779406.\n",
      "[I 2024-11-29 21:45:39,124] Trial 23 finished with value: 0.5684673752194457 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'p': 1}. Best is trial 18 with value: 0.5956019045779406.\n",
      "[I 2024-11-29 21:45:39,139] Trial 24 finished with value: 0.574981778703924 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'p': 1}. Best is trial 18 with value: 0.5956019045779406.\n",
      "[I 2024-11-29 21:45:39,155] Trial 25 finished with value: 0.5989961386499442 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,170] Trial 26 finished with value: 0.5989961386499442 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,185] Trial 27 finished with value: 0.5989961386499442 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,201] Trial 28 finished with value: 0.5565328658597688 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,217] Trial 29 finished with value: 0.5102942363723683 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 2}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,233] Trial 30 finished with value: 0.5326410970973 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,249] Trial 31 finished with value: 0.5989961386499442 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,264] Trial 32 finished with value: 0.574981778703924 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,280] Trial 33 finished with value: 0.5989961386499442 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,295] Trial 34 finished with value: 0.580908994303257 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,311] Trial 35 finished with value: 0.5989961386499442 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,328] Trial 36 finished with value: 0.5565328658597688 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,345] Trial 37 finished with value: 0.5160096750709215 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'p': 2}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,365] Trial 38 finished with value: 0.48592892598998755 and parameters: {'n_neighbors': 26, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,387] Trial 39 finished with value: 0.5103165446659788 and parameters: {'n_neighbors': 21, 'weights': 'distance', 'p': 1}. Best is trial 25 with value: 0.5989961386499442.\n",
      "[I 2024-11-29 21:45:39,404] Trial 40 finished with value: 0.6063697930171672 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 40 with value: 0.6063697930171672.\n",
      "[I 2024-11-29 21:45:39,422] Trial 41 finished with value: 0.6063697930171672 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 40 with value: 0.6063697930171672.\n",
      "[I 2024-11-29 21:45:39,438] Trial 42 finished with value: 0.6063697930171672 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 40 with value: 0.6063697930171672.\n",
      "[I 2024-11-29 21:45:39,456] Trial 43 finished with value: 0.6093210995078839 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 43 with value: 0.6093210995078839.\n",
      "[I 2024-11-29 21:45:39,472] Trial 44 finished with value: 0.6093210995078839 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 43 with value: 0.6093210995078839.\n",
      "[I 2024-11-29 21:45:39,488] Trial 45 finished with value: 0.5378620946773863 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'p': 1}. Best is trial 43 with value: 0.6093210995078839.\n",
      "[I 2024-11-29 21:45:39,506] Trial 46 finished with value: 0.6093210995078839 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 43 with value: 0.6093210995078839.\n",
      "[I 2024-11-29 21:45:39,527] Trial 47 finished with value: 0.6149285970110036 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'p': 1}. Best is trial 47 with value: 0.6149285970110036.\n",
      "[I 2024-11-29 21:45:39,545] Trial 48 finished with value: 0.4907458634205133 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'p': 2}. Best is trial 47 with value: 0.6149285970110036.\n",
      "[I 2024-11-29 21:45:39,560] Trial 49 finished with value: 0.5684673752194457 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'p': 1}. Best is trial 47 with value: 0.6149285970110036.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for KNN: {'n_neighbors': 5, 'weights': 'distance', 'p': 1}\n",
      "Best R^2 score for KNN: 0.6149285970110036\n",
      "MSE for KNN: 20.998923397039146\n"
     ]
    }
   ],
   "source": [
    "# Optimize KNN Regressor\n",
    "knn_study = optuna.create_study(direction='maximize')\n",
    "knn_study.optimize(knn_objective, n_trials=50)\n",
    "print(\"Best parameters for KNN:\", knn_study.best_params)\n",
    "print(\"Best R^2 score for KNN:\", knn_study.best_value)\n",
    "\n",
    "# Train and evaluate KNN on test set\n",
    "knn_model = KNeighborsRegressor(**knn_study.best_params)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "knn_mse = mean_squared_error(y_test, y_pred_knn)\n",
    "print(\"MSE for KNN:\", knn_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-29 21:45:45,814] A new study created in memory with name: no-name-94b6f053-2b7f-4998-8985-6d3588b58a39\n",
      "[I 2024-11-29 21:45:45,983] Trial 0 finished with value: 0.5406886841549042 and parameters: {'n_estimators': 70, 'max_depth': 1, 'min_samples_split': 10}. Best is trial 0 with value: 0.5406886841549042.\n",
      "[I 2024-11-29 21:45:46,423] Trial 1 finished with value: 0.5462575950402424 and parameters: {'n_estimators': 175, 'max_depth': 1, 'min_samples_split': 10}. Best is trial 1 with value: 0.5462575950402424.\n",
      "[I 2024-11-29 21:45:47,487] Trial 2 finished with value: 0.8195392588701113 and parameters: {'n_estimators': 194, 'max_depth': 19, 'min_samples_split': 8}. Best is trial 2 with value: 0.8195392588701113.\n",
      "[I 2024-11-29 21:45:48,414] Trial 3 finished with value: 0.8218126426009859 and parameters: {'n_estimators': 158, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 3 with value: 0.8218126426009859.\n",
      "[I 2024-11-29 21:45:48,854] Trial 4 finished with value: 0.8007543712288328 and parameters: {'n_estimators': 117, 'max_depth': 4, 'min_samples_split': 3}. Best is trial 3 with value: 0.8218126426009859.\n",
      "[I 2024-11-29 21:45:49,823] Trial 5 finished with value: 0.8194862211769245 and parameters: {'n_estimators': 168, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 3 with value: 0.8218126426009859.\n",
      "[I 2024-11-29 21:45:50,270] Trial 6 finished with value: 0.8228386090116053 and parameters: {'n_estimators': 69, 'max_depth': 16, 'min_samples_split': 3}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:50,936] Trial 7 finished with value: 0.8206639749508557 and parameters: {'n_estimators': 113, 'max_depth': 12, 'min_samples_split': 6}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:52,000] Trial 8 finished with value: 0.8189672267207765 and parameters: {'n_estimators': 196, 'max_depth': 16, 'min_samples_split': 9}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:53,060] Trial 9 finished with value: 0.8197719604043003 and parameters: {'n_estimators': 199, 'max_depth': 8, 'min_samples_split': 3}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:53,232] Trial 10 finished with value: 0.8148089565829075 and parameters: {'n_estimators': 24, 'max_depth': 20, 'min_samples_split': 2}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:53,650] Trial 11 finished with value: 0.8207393928774147 and parameters: {'n_estimators': 68, 'max_depth': 14, 'min_samples_split': 4}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:54,362] Trial 12 finished with value: 0.8187898356890688 and parameters: {'n_estimators': 131, 'max_depth': 8, 'min_samples_split': 2}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:54,737] Trial 13 finished with value: 0.819890924131496 and parameters: {'n_estimators': 62, 'max_depth': 16, 'min_samples_split': 5}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:55,607] Trial 14 finished with value: 0.821168361430994 and parameters: {'n_estimators': 144, 'max_depth': 12, 'min_samples_split': 4}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:56,025] Trial 15 finished with value: 0.8143766803774986 and parameters: {'n_estimators': 88, 'max_depth': 6, 'min_samples_split': 7}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:56,202] Trial 16 finished with value: 0.8168703441044437 and parameters: {'n_estimators': 25, 'max_depth': 16, 'min_samples_split': 3}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:56,479] Trial 17 finished with value: 0.8179265909630345 and parameters: {'n_estimators': 44, 'max_depth': 13, 'min_samples_split': 5}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:57,009] Trial 18 finished with value: 0.8217203109990712 and parameters: {'n_estimators': 91, 'max_depth': 9, 'min_samples_split': 2}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:58,003] Trial 19 finished with value: 0.8194542666278057 and parameters: {'n_estimators': 161, 'max_depth': 18, 'min_samples_split': 4}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:58,594] Trial 20 finished with value: 0.8089251543917889 and parameters: {'n_estimators': 140, 'max_depth': 5, 'min_samples_split': 6}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:59,189] Trial 21 finished with value: 0.8209582931503749 and parameters: {'n_estimators': 96, 'max_depth': 10, 'min_samples_split': 2}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:59,637] Trial 22 finished with value: 0.8211730313454663 and parameters: {'n_estimators': 77, 'max_depth': 9, 'min_samples_split': 3}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:45:59,882] Trial 23 finished with value: 0.8137212420135315 and parameters: {'n_estimators': 43, 'max_depth': 7, 'min_samples_split': 2}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:46:00,483] Trial 24 finished with value: 0.8220788913376804 and parameters: {'n_estimators': 100, 'max_depth': 14, 'min_samples_split': 4}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:46:01,195] Trial 25 finished with value: 0.8201366044681334 and parameters: {'n_estimators': 118, 'max_depth': 14, 'min_samples_split': 4}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:46:01,513] Trial 26 finished with value: 0.8202660858095197 and parameters: {'n_estimators': 49, 'max_depth': 15, 'min_samples_split': 3}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:46:02,123] Trial 27 finished with value: 0.8215253129286164 and parameters: {'n_estimators': 106, 'max_depth': 18, 'min_samples_split': 6}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:46:03,005] Trial 28 finished with value: 0.8219804943520179 and parameters: {'n_estimators': 148, 'max_depth': 12, 'min_samples_split': 4}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:46:03,839] Trial 29 finished with value: 0.8188259901900548 and parameters: {'n_estimators': 138, 'max_depth': 12, 'min_samples_split': 5}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:46:04,342] Trial 30 finished with value: 0.8192876630581086 and parameters: {'n_estimators': 81, 'max_depth': 17, 'min_samples_split': 4}. Best is trial 6 with value: 0.8228386090116053.\n",
      "[I 2024-11-29 21:46:05,340] Trial 31 finished with value: 0.824349063339878 and parameters: {'n_estimators': 155, 'max_depth': 14, 'min_samples_split': 3}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:06,107] Trial 32 finished with value: 0.8183871030325307 and parameters: {'n_estimators': 131, 'max_depth': 14, 'min_samples_split': 4}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:06,682] Trial 33 finished with value: 0.8209910946855727 and parameters: {'n_estimators': 103, 'max_depth': 13, 'min_samples_split': 7}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:07,857] Trial 34 finished with value: 0.8217127387497237 and parameters: {'n_estimators': 181, 'max_depth': 15, 'min_samples_split': 3}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:08,655] Trial 35 finished with value: 0.819056405694301 and parameters: {'n_estimators': 155, 'max_depth': 11, 'min_samples_split': 10}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:09,255] Trial 36 finished with value: 0.7759197485346039 and parameters: {'n_estimators': 185, 'max_depth': 3, 'min_samples_split': 5}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:10,042] Trial 37 finished with value: 0.8225977979731006 and parameters: {'n_estimators': 126, 'max_depth': 17, 'min_samples_split': 3}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:10,801] Trial 38 finished with value: 0.8221141243439567 and parameters: {'n_estimators': 120, 'max_depth': 20, 'min_samples_split': 3}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:11,851] Trial 39 finished with value: 0.8220869594715048 and parameters: {'n_estimators': 167, 'max_depth': 20, 'min_samples_split': 3}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:12,670] Trial 40 finished with value: 0.8204685805712593 and parameters: {'n_estimators': 125, 'max_depth': 19, 'min_samples_split': 2}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:13,735] Trial 41 finished with value: 0.822186806148717 and parameters: {'n_estimators': 172, 'max_depth': 20, 'min_samples_split': 3}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:14,791] Trial 42 finished with value: 0.8224793260552458 and parameters: {'n_estimators': 171, 'max_depth': 18, 'min_samples_split': 3}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:15,864] Trial 43 finished with value: 0.8217037222110392 and parameters: {'n_estimators': 175, 'max_depth': 18, 'min_samples_split': 3}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:17,112] Trial 44 finished with value: 0.821403885981969 and parameters: {'n_estimators': 188, 'max_depth': 17, 'min_samples_split': 2}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:18,182] Trial 45 finished with value: 0.8224009991958562 and parameters: {'n_estimators': 171, 'max_depth': 19, 'min_samples_split': 3}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:19,193] Trial 46 finished with value: 0.8231339633244679 and parameters: {'n_estimators': 154, 'max_depth': 17, 'min_samples_split': 2}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:20,226] Trial 47 finished with value: 0.8224889124882531 and parameters: {'n_estimators': 160, 'max_depth': 17, 'min_samples_split': 2}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:21,066] Trial 48 finished with value: 0.8184172584747686 and parameters: {'n_estimators': 160, 'max_depth': 16, 'min_samples_split': 9}. Best is trial 31 with value: 0.824349063339878.\n",
      "[I 2024-11-29 21:46:22,073] Trial 49 finished with value: 0.8235515278185723 and parameters: {'n_estimators': 153, 'max_depth': 17, 'min_samples_split': 2}. Best is trial 31 with value: 0.824349063339878.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'n_estimators': 155, 'max_depth': 14, 'min_samples_split': 3}\n",
      "Best R^2 score for Random Forest: 0.824349063339878\n",
      "MSE for Random Forest: 8.410549834140857\n"
     ]
    }
   ],
   "source": [
    "# Optimize Random Forest Regressor\n",
    "rf_study = optuna.create_study(direction='maximize')\n",
    "rf_study.optimize(rf_objective, n_trials=50)\n",
    "print(\"Best parameters for Random Forest:\", rf_study.best_params)\n",
    "print(\"Best R^2 score for Random Forest:\", rf_study.best_value)\n",
    "\n",
    "# Train and evaluate Random Forest on test set\n",
    "rf_model = RandomForestRegressor(**rf_study.best_params, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, y_pred_rf)\n",
    "print(\"MSE for Random Forest:\", rf_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-29 21:46:22,303] A new study created in memory with name: no-name-a235ab23-42a9-4fd0-aac0-f0a0a2b09738\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,314] Trial 0 finished with value: 0.7110607218486449 and parameters: {'alpha': 0.010356765022210486, 'solver': 'lsqr'}. Best is trial 0 with value: 0.7110607218486449.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,326] Trial 1 finished with value: 0.7148029015970678 and parameters: {'alpha': 6.794640119082117, 'solver': 'auto'}. Best is trial 1 with value: 0.7148029015970678.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-11-29 21:46:22,450] Trial 2 finished with value: 0.6883865033252701 and parameters: {'alpha': 0.026442705273027632, 'solver': 'sag'}. Best is trial 1 with value: 0.7148029015970678.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,458] Trial 3 finished with value: 0.7237250790381571 and parameters: {'alpha': 0.19188520274472345, 'solver': 'svd'}. Best is trial 3 with value: 0.7237250790381571.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,466] Trial 4 finished with value: 0.7244316771003964 and parameters: {'alpha': 0.001532315404723393, 'solver': 'cholesky'}. Best is trial 4 with value: 0.7244316771003964.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,475] Trial 5 finished with value: 0.7118398244728208 and parameters: {'alpha': 5.681783878589312, 'solver': 'lsqr'}. Best is trial 4 with value: 0.7244316771003964.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,484] Trial 6 finished with value: 0.7244182167708708 and parameters: {'alpha': 0.006517361765157564, 'solver': 'auto'}. Best is trial 4 with value: 0.7244316771003964.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-11-29 21:46:22,599] Trial 7 finished with value: 0.6883871093504271 and parameters: {'alpha': 0.01756746651580896, 'solver': 'sag'}. Best is trial 4 with value: 0.7244316771003964.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,607] Trial 8 finished with value: 0.7234370628560567 and parameters: {'alpha': 0.25691522629536645, 'solver': 'svd'}. Best is trial 4 with value: 0.7244316771003964.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,614] Trial 9 finished with value: 0.7243810714922734 and parameters: {'alpha': 0.019573350714860393, 'solver': 'auto'}. Best is trial 4 with value: 0.7244316771003964.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,625] Trial 10 finished with value: 0.7244312755564332 and parameters: {'alpha': 0.001683294495691133, 'solver': 'cholesky'}. Best is trial 4 with value: 0.7244316771003964.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,634] Trial 11 finished with value: 0.7244330544934352 and parameters: {'alpha': 0.0010133094327349915, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,644] Trial 12 finished with value: 0.7244328011519297 and parameters: {'alpha': 0.0011088990869179652, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,654] Trial 13 finished with value: 0.7244327142367932 and parameters: {'alpha': 0.001141679982132482, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,664] Trial 14 finished with value: 0.7214235261995976 and parameters: {'alpha': 0.7256188818417219, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,674] Trial 15 finished with value: 0.7244255977055103 and parameters: {'alpha': 0.00380287088991224, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,684] Trial 16 finished with value: 0.7241936845353527 and parameters: {'alpha': 0.07613332101841558, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,694] Trial 17 finished with value: 0.7244249261430952 and parameters: {'alpha': 0.004051723169032239, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,704] Trial 18 finished with value: 0.7195639148591115 and parameters: {'alpha': 1.3049776344109665, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,716] Trial 19 finished with value: 0.7110734504244253 and parameters: {'alpha': 0.0703330646058481, 'solver': 'lsqr'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,726] Trial 20 finished with value: 0.7244280728935522 and parameters: {'alpha': 0.0028823350259250275, 'solver': 'svd'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,737] Trial 21 finished with value: 0.7244330466574624 and parameters: {'alpha': 0.0010162669467763813, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,746] Trial 22 finished with value: 0.724432645897265 and parameters: {'alpha': 0.0011674500589616288, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,757] Trial 23 finished with value: 0.7244281545474548 and parameters: {'alpha': 0.0028518771129023056, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-11-29 21:46:22,877] Trial 24 finished with value: 0.6883877110278254 and parameters: {'alpha': 0.008755832400982086, 'solver': 'sag'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,887] Trial 25 finished with value: 0.7244296688189583 and parameters: {'alpha': 0.0022859750712282394, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,898] Trial 26 finished with value: 0.7244175980402767 and parameters: {'alpha': 0.006742903428311396, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,907] Trial 27 finished with value: 0.7243351388601559 and parameters: {'alpha': 0.0346164326117026, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,918] Trial 28 finished with value: 0.7244327485935147 and parameters: {'alpha': 0.0011287228330236954, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,929] Trial 29 finished with value: 0.7110612807880894 and parameters: {'alpha': 0.012979706109805809, 'solver': 'lsqr'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,940] Trial 30 finished with value: 0.724423674451012 and parameters: {'alpha': 0.004514529635146672, 'solver': 'auto'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,949] Trial 31 finished with value: 0.7244330042205025 and parameters: {'alpha': 0.0010322828584358411, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,959] Trial 32 finished with value: 0.724433048234787 and parameters: {'alpha': 0.0010156716251211225, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:22,969] Trial 33 finished with value: 0.7244299471793044 and parameters: {'alpha': 0.0021817281276320702, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-11-29 21:46:23,086] Trial 34 finished with value: 0.6883881634406371 and parameters: {'alpha': 0.0021301464377616926, 'solver': 'sag'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,097] Trial 35 finished with value: 0.724424694523639 and parameters: {'alpha': 0.004137462757451121, 'solver': 'svd'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,107] Trial 36 finished with value: 0.7244309593711385 and parameters: {'alpha': 0.0018020768377021445, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,118] Trial 37 finished with value: 0.7110599151244796 and parameters: {'alpha': 0.006572769695076861, 'solver': 'lsqr'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,129] Trial 38 finished with value: 0.7141523115296458 and parameters: {'alpha': 9.73179852642968, 'solver': 'auto'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,139] Trial 39 finished with value: 0.7244329974945922 and parameters: {'alpha': 0.0010348210976164488, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\GOD\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-11-29 21:46:23,256] Trial 40 finished with value: 0.688386170620955 and parameters: {'alpha': 0.03131513001900911, 'solver': 'sag'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,267] Trial 41 finished with value: 0.7244313812203569 and parameters: {'alpha': 0.0016435793376901368, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,277] Trial 42 finished with value: 0.7244318244091176 and parameters: {'alpha': 0.0014768913399198606, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,286] Trial 43 finished with value: 0.7244329654500172 and parameters: {'alpha': 0.0010469135828821267, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,296] Trial 44 finished with value: 0.7244266625309456 and parameters: {'alpha': 0.0034075035681536163, 'solver': 'cholesky'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,307] Trial 45 finished with value: 0.7244054763984193 and parameters: {'alpha': 0.011102538307987419, 'solver': 'svd'}. Best is trial 11 with value: 0.7244330544934352.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,317] Trial 46 finished with value: 0.724433088845696 and parameters: {'alpha': 0.0010003432697729975, 'solver': 'cholesky'}. Best is trial 46 with value: 0.724433088845696.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,328] Trial 47 finished with value: 0.7168785252551257 and parameters: {'alpha': 2.8998557086961396, 'solver': 'auto'}. Best is trial 46 with value: 0.724433088845696.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,337] Trial 48 finished with value: 0.7231791666933105 and parameters: {'alpha': 0.3139996385458481, 'solver': 'cholesky'}. Best is trial 46 with value: 0.724433088845696.\n",
      "C:\\Users\\GOD\\AppData\\Local\\Temp\\ipykernel_17588\\1874159057.py:20: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2024-11-29 21:46:23,348] Trial 49 finished with value: 0.7244313322660882 and parameters: {'alpha': 0.0016619806857707928, 'solver': 'cholesky'}. Best is trial 46 with value: 0.724433088845696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Ridge: {'alpha': 0.0010003432697729975, 'solver': 'cholesky'}\n",
      "Best R^2 score for Ridge: 0.724433088845696\n",
      "MSE for Ridge: 24.29117573572531\n"
     ]
    }
   ],
   "source": [
    "# Optimize Ridge Regressor\n",
    "ridge_study = optuna.create_study(direction='maximize')\n",
    "ridge_study.optimize(ridge_objective, n_trials=50)\n",
    "print(\"Best parameters for Ridge:\", ridge_study.best_params)\n",
    "print(\"Best R^2 score for Ridge:\", ridge_study.best_value)\n",
    "\n",
    "# Train and evaluate Ridge on test set\n",
    "ridge_model = Ridge(**ridge_study.best_params, random_state=42)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "ridge_mse = mean_squared_error(y_test, y_pred_ridge)\n",
    "print(\"MSE for Ridge:\", ridge_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non Hyper Tuned models\n",
    "            Model                               MSE       R-Squared\n",
    "    - Linear Regression                       24.291117   0.668760\n",
    "    - SGD Regression                          24.875080   0.660796\n",
    "    - Linear Regression (Dropped Features)    25.400905   0.653626\n",
    "    - SGD Regression (Dropped Features)       25.640159   0.650364\n",
    "    - Linear Regression (PCA)                 30.109735   0.589415\n",
    "    - SGD Regression (PCA)                    30.254352   0.587443\n",
    "    - Linear Regression (One-Hot Encoded)     24.291117   0.668760\n",
    "\n",
    "# Optuna Optimized Models\n",
    "## Random Forest \n",
    "    Based on the above code the best model seems to be Random Forest with the following result\n",
    "    Best parameters for Ridge: {'alpha': 0.0010031859321893023, 'solver': 'cholesky'}\n",
    "    Best R^2 score for Random Forest: 0.8245965893254837\n",
    "    MSE for Random Forest: 8.046527166338901\n",
    "## Ridge\n",
    "    Best parameters for Ridge: {'alpha': 0.0010031859321893023, 'solver': 'cholesky'}\n",
    "    Best R^2 score for Ridge: 0.7244330813146554\n",
    "    MSE for Ridge: 24.291175903056494\n",
    "## KNN\n",
    "    Best parameters for KNN: {'n_neighbors': 5, 'weights': 'distance', 'p': 1}\n",
    "    Best R^2 score for KNN: 0.6149285970110036\n",
    "    MSE for KNN: 20.998923397039146\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is Random Forest with R^2 score: 0.824349063339878 and MSE: 8.410549834140857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_model_random forest.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare models and save the best one\n",
    "best_model = None\n",
    "best_score = -np.inf\n",
    "\n",
    "# Check KNN\n",
    "if knn_study.best_value > best_score:\n",
    "    best_model = knn_model\n",
    "    best_score = knn_study.best_value\n",
    "    best_model_name = 'KNN'\n",
    "    best_mse = knn_mse\n",
    "\n",
    "# Check Random Forest\n",
    "if rf_study.best_value > best_score:\n",
    "    best_model = rf_model\n",
    "    best_score = rf_study.best_value\n",
    "    best_model_name = 'Random Forest'\n",
    "    best_mse = rf_mse\n",
    "\n",
    "# Check Ridge\n",
    "if ridge_study.best_value > best_score:\n",
    "    best_model = ridge_model\n",
    "    best_score = ridge_study.best_value\n",
    "    best_model_name = 'Ridge'\n",
    "    best_mse = ridge_mse\n",
    "\n",
    "# Save the best model\n",
    "print(f\"Best model is {best_model_name} with R^2 score: {best_score} and MSE: {best_mse}\")\n",
    "joblib.dump(best_model, f'model/best_model_{best_model_name.lower()}.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Flask code please refer\n",
    "```py\n",
    "import optuna\n",
    "import joblib\n",
    "from flask import Flask, request, render_template, redirect, url_for\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model = joblib.load('model/best_model_random_forest.pkl')\n",
    "\n",
    "columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PT', 'B', 'LSTAT']\n",
    "\n",
    "# Create Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        input_format = request.form.get(\"inputFormat\")\n",
    "        if input_format == \"json\":\n",
    "            \n",
    "            json_data = request.form[\"jsonData\"]\n",
    "            input_data = pd.read_json(json_data)\n",
    "        else:\n",
    "            \n",
    "            input_data = [\n",
    "                float(request.form[column]) for column in columns\n",
    "            ]\n",
    "            input_data = pd.DataFrame([input_data], columns=columns)\n",
    "        \n",
    "     \n",
    "        predictions = model.predict(input_data)\n",
    "        prediction_texts = [f'Predicted Median Value of Owner-Occupied Homes: ${pred:.2f}' for pred in predictions]\n",
    "        return render_template('result.html', prediction_text=prediction_texts)\n",
    "    except Exception as e:\n",
    "        return render_template('result.html', prediction_text=[f'Error occurred: {str(e)}'])\n",
    "\n",
    "@app.route('/result')\n",
    "def prediction_result():\n",
    "    prediction_text = request.args.get('prediction_text')\n",
    "    return render_template('result.html', prediction_text=prediction_text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Frontend Webpage - Index.html\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Boston Housing Price Prediction</title>\n",
    "    <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css\">\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h2 class=\"text-center mt-4\">Boston Housing Price Prediction</h2>\n",
    "        <form action=\"/predict\" method=\"post\">\n",
    "            <div class=\"form-group\">\n",
    "                <label for=\"inputFormat\">Input Format:</label>\n",
    "                <select class=\"form-control\" id=\"inputFormat\" name=\"inputFormat\" onchange=\"toggleInputFields()\">\n",
    "                    <option value=\"manual\">Manual Entry</option>\n",
    "                    <option value=\"json\">JSON Input</option>\n",
    "                </select>\n",
    "            </div>\n",
    "\n",
    "            <div id=\"manualInput\">\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"CRIM\">CRIM (Per capita crime rate by town):</label>\n",
    "                    <input type=\"number\" step=\"0.01\" class=\"form-control\" id=\"CRIM\" name=\"CRIM\">\n",
    "                </div>\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"ZN\">ZN (Proportion of residential land zoned for lots over 25,000 sq. ft.):</label>\n",
    "                    <input type=\"number\" step=\"0.01\" class=\"form-control\" id=\"ZN\" name=\"ZN\">\n",
    "                </div>\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"INDUS\">INDUS (Proportion of non-retail business acres per town):</label>\n",
    "                    <input type=\"number\" step=\"0.01\" class=\"form-control\" id=\"INDUS\" name=\"INDUS\">\n",
    "                </div>\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"CHAS\">CHAS (Charles River dummy variable [1 if tract bounds river; 0 otherwise]):</label>\n",
    "                    <input type=\"number\" step=\"1\" class=\"form-control\" id=\"CHAS\" name=\"CHAS\">\n",
    "                </div>\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"NOX\">NOX (Nitric oxide concentration [parts per 10 million]):</label>\n",
    "                    <input type=\"number\" step=\"0.001\" class=\"form-control\" id=\"NOX\" name=\"NOX\">\n",
    "                </div>\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"RM\">RM (Average number of rooms per dwelling):</label>\n",
    "                    <input type=\"number\" step=\"0.01\" class=\"form-control\" id=\"RM\" name=\"RM\">\n",
    "                </div>\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"AGE\">AGE (Proportion of owner-occupied units built before 1940):</label>\n",
    "                    <input type=\"number\" step=\"0.01\" class=\"form-control\" id=\"AGE\" name=\"AGE\">\n",
    "                </div>\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"DIS\">DIS (Weighted distances to five Boston employment centers):</label>\n",
    "                    <input type=\"number\" step=\"0.01\" class=\"form-control\" id=\"DIS\" name=\"DIS\">\n",
    "                </div>\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"RAD\">RAD (Index of accessibility to radial highways):</label>\n",
    "                    <input type=\"number\" step=\"1\" class=\"form-control\" id=\"RAD\" name=\"RAD\">\n",
    "                </div>\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"TAX\">TAX (Full-value property-tax rate per $10,000):</label>\n",
    "                    <input type=\"number\" step=\"1\" class=\"form-control\" id=\"TAX\" name=\"TAX\">\n",
    "                </div>\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"PTRATIO\">PTRATIO (Pupil-teacher ratio by town):</label>\n",
    "                    <input type=\"number\" step=\"0.01\" class=\"form-control\" id=\"PTRATIO\" name=\"PTRATIO\">\n",
    "                </div>\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"B\">B (1000(Bk - 0.63)^2, where Bk is the proportion of Black people by town):</label>\n",
    "                    <input type=\"number\" step=\"0.01\" class=\"form-control\" id=\"B\" name=\"B\">\n",
    "                </div>\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"LSTAT\">LSTAT (Percentage of lower status of the population):</label>\n",
    "                    <input type=\"number\" step=\"0.01\" class=\"form-control\" id=\"LSTAT\" name=\"LSTAT\">\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <div id=\"jsonInput\" style=\"display: none;\">\n",
    "                <div class=\"form-group\">\n",
    "                    <label for=\"jsonData\">Enter Input Data in JSON Format (for multiple rows, use an array of JSON objects):</label>\n",
    "                    <textarea class=\"form-control\" id=\"jsonData\" name=\"jsonData\" rows=\"10\"></textarea>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <button type=\"submit\" class=\"btn btn-primary\">Predict</button>\n",
    "        </form>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"container text-center mt-5\">\n",
    "        <a href=\"/\" class=\"btn btn-secondary\">Predict Another Value</a>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        function toggleInputFields() {\n",
    "            var inputFormat = document.getElementById(\"inputFormat\").value;\n",
    "            if (inputFormat === \"manual\") {\n",
    "                document.getElementById(\"manualInput\").style.display = \"block\";\n",
    "                document.getElementById(\"jsonInput\").style.display = \"none\";\n",
    "            } else {\n",
    "                document.getElementById(\"manualInput\").style.display = \"none\";\n",
    "                document.getElementById(\"jsonInput\").style.display = \"block\";\n",
    "            }\n",
    "        }\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Frontend Webpage - Result.html\n",
    "```html\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Prediction Result</title>\n",
    "    <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css\">\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <h2 class=\"text-center mt-4\">Prediction Results</h2>\n",
    "        <div class=\"mt-4\">\n",
    "            {% if prediction_text %}\n",
    "                <ul class=\"list-group\">\n",
    "                    {% for text in prediction_text %}\n",
    "                        <li class=\"list-group-item text-success\">{{ text }}</li>\n",
    "                    {% endfor %}\n",
    "                </ul>\n",
    "            {% endif %}\n",
    "        </div>\n",
    "        <div class=\"mt-4 text-center\">\n",
    "            <a href=\"/\" class=\"btn btn-primary\">Predict Another Value</a>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the Flask result please Refer the Image folder or use the below as reference\n",
    "![Maunal Entry](images/Manual_Entry.png)\n",
    "![Single Json](images/Single_json.png)\n",
    "![Multi Json](images/Multi_json.png)\n",
    "![Result](images/Result.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
